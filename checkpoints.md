#### Парсинг данных и EDA
1. Сделать [обзор литературы](https://docs.google.com/document/d/1NGa4D-8iVcYtnW0FPB_9Ytw0kxDtCm0l7aKy4JKtYBU/edit?tab=t.8n2zegdidvu1#heading=h.xzk2mno31nic)
2. Спарсить видео с РЖЯ и субтитрами с Ютюба
3. Осознать и описать датасет
   
#### ML
6. Попробовать кластеризовать полученный датасет (скорее всего получим исходную инфу о том, откуда какой кусочек видео хаха)
7. Сделать бейзлайн по ретривалу только по сопровождающему тексту: по словам / наличию кавычек <-> реф. сдвиг и т.д. (если сопровождающего текста нет - его можно сгенерировать существующими системами перевода)

#### DL
**Примерная модель** (cf. [Gesture2Vec](https://github.com/pjyazdian/Gesture2Vec?tab=readme-ov-file)):
- модель текстовых эмбеддингов
- модель эмбеддингов изображений
- трансформерная архитектура поверх
- выход классификатора

**Принцип обучения** (cf. word2vec):
Contrastive learning:
- positive sampling: фрагмент текста, соответствующий отрезку видео должен на выходе классификатора давать 1
- negative sampling: фрагмент текста из другого видео/другой части на выходе классификатор давать 0
- Можно попробовать triplet loss

Замеры: 
- считать временнОе пересечение найденных кусков видео с таргетными (cf. mAP)
- считать AUC ROC на основе значений классификатора
  
#### Системная часть
Стандартный фронтэнд поискового движка

#### Back Log
???
